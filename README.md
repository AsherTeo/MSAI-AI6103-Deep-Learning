# MSAI-AI6103-Deep-Learning

In the first assignment, we are required to train a classifier using Resnet-18 to predict the classes in Cifar-10 datasets. After that, we improved the prediction accuracy by finetuning the hyper-parameters. The hyper-parameters consists of different learning rate, different learning rate schedule, different weight decay values and data augmentation. 

For the Project, my task was to research and experiment 4 to 5 different Regularization methods using Resnet-18. The purpose of Regularization is to prevent overfitting issue as overfitting is a major problem in neural network that usually resulting good training losses and accuracy but poor testing or validation accuracy and losses.
The cause of overfitting is mainly due to the either lack of training datasets, training and testing datasets are not in the same distribution or the model learned noise in the training datasets. The common solutions for overfitting are mainly early stopping, data augmentation, regularization and dropout.
Therefore, the four methods that I will be using are mainly Stable Weight Decay, Jacobian Regularization, CutMix Augmentation and Drop Block. For more information, please refer to my PDF under Project.

Overall Grade B+
